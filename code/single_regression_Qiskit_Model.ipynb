{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IxcD-feXlRg3"
      },
      "outputs": [],
      "source": [
        "!pip -q install \"qiskit>=1.0\" \"qiskit-aer>=0.14\" pandas"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vCcppfoumNUg",
        "outputId": "74da4b4f-c4e7-4a28-e437-94c13537c91d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, json, math, random, time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from qiskit import QuantumCircuit\n",
        "from qiskit.quantum_info import Statevector, SparsePauliOp\n",
        "\n",
        "from qiskit_aer import AerSimulator\n",
        "from qiskit_aer.noise import NoiseModel\n",
        "from qiskit_aer.noise.errors import depolarizing_error, pauli_error, amplitude_damping_error\n",
        "\n",
        "from qiskit import qpy\n",
        "import io\n",
        "import base64\n",
        "\n",
        "# =========================\n",
        "# 재현성(시드 고정)\n",
        "# =========================\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "\n",
        "# =========================\n",
        "# 저장 경로\n",
        "# =========================\n",
        "OUT_DIR = \"/content/drive/MyDrive/qem_dataset\"\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "\n",
        "OUT_CSV = os.path.join(OUT_DIR, \"dataset_raw.csv\")\n",
        "OUT_META = os.path.join(OUT_DIR, \"run_meta.json\")\n",
        "\n",
        "print(\"OUT_DIR:\", OUT_DIR)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "71IyFGWZmjeL",
        "outputId": "80db9b89-2cba-4658-da0e-645eef816bd7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OUT_DIR: /content/drive/MyDrive/qem_dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "GATE_POOL_1Q = [\"rx\", \"ry\", \"rz\", \"x\", \"y\", \"z\"]\n",
        "GATE_POOL_2Q = [\"cx\"]\n",
        "\n",
        "def random_2q_circuit(depth: int, p_cx: float = 0.25) -> QuantumCircuit:\n",
        "    \"\"\"\n",
        "    depth 만큼 랜덤하게 게이트를 쌓는 2-qubit 회로 생성\n",
        "    - p_cx 확률로 CX, 나머지는 1-qubit gate\n",
        "    - Rx/Ry/Rz는 angle ~ Uniform(0, 2π)\n",
        "    \"\"\"\n",
        "    qc = QuantumCircuit(2)\n",
        "\n",
        "    for _ in range(depth):\n",
        "        use_cx = (random.random() < p_cx)\n",
        "        if use_cx:\n",
        "            # control/target 랜덤\n",
        "            if random.random() < 0.5:\n",
        "                qc.cx(0, 1)\n",
        "            else:\n",
        "                qc.cx(1, 0)\n",
        "        else:\n",
        "            g = random.choice(GATE_POOL_1Q)\n",
        "            q = random.choice([0, 1])\n",
        "\n",
        "            if g in [\"rx\", \"ry\", \"rz\"]:\n",
        "                theta = random.uniform(0, 2 * math.pi)\n",
        "                getattr(qc, g)(theta, q)\n",
        "            else:\n",
        "                getattr(qc, g)(q)\n",
        "\n",
        "    return qc"
      ],
      "metadata": {
        "id": "hmj77tRunUdP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NOISE_CLASSES = [\"noiseless\", \"pauli\", \"depol\", \"amp_damp\"]\n",
        "\n",
        "def sample_noise_params(noise_class: str):\n",
        "    \"\"\"\n",
        "    노이즈 강도 샘플링 (원하는 범위로 조절 가능)\n",
        "    - depol: p in [0.001, 0.02]\n",
        "    - pauli: p in [0.001, 0.02] (X/Y/Z 균등)\n",
        "    - amp_damp: gamma in [0.001, 0.05]\n",
        "    \"\"\"\n",
        "    if noise_class == \"depol\":\n",
        "        p = random.uniform(0.001, 0.02)\n",
        "        return {\"p\": p}\n",
        "    if noise_class == \"pauli\":\n",
        "        p = random.uniform(0.001, 0.02)\n",
        "        # X/Y/Z 균등, I는 1-p\n",
        "        return {\"px\": p/3, \"py\": p/3, \"pz\": p/3}\n",
        "    if noise_class == \"amp_damp\":\n",
        "        gamma = random.uniform(0.001, 0.05)\n",
        "        return {\"gamma\": gamma}\n",
        "    return {}  # noiseless\n",
        "\n",
        "def build_noise_model(noise_class: str, params: dict) -> NoiseModel:\n",
        "    \"\"\"\n",
        "    Qiskit Aer NoiseModel 생성.\n",
        "    간단/재현성 좋게: 주로 1-qubit 게이트에 노이즈를 붙이고,\n",
        "    CX에는 depol일 때만 2-qubit depolarizing을 약하게 추가(옵션).\n",
        "    \"\"\"\n",
        "    nm = NoiseModel()\n",
        "\n",
        "    oneq_gates = [\"rx\", \"ry\", \"rz\", \"x\", \"y\", \"z\"]\n",
        "    twoq_gates = [\"cx\"]\n",
        "\n",
        "    if noise_class == \"noiseless\":\n",
        "        return nm\n",
        "\n",
        "    if noise_class == \"depol\":\n",
        "        p = params[\"p\"]\n",
        "        err1 = depolarizing_error(p, 1)\n",
        "        # 2-qubit은 보통 더 약/강하게 설정 가능. 여기선 예시로 p2=2p (원하면 바꿔)\n",
        "        err2 = depolarizing_error(min(1.0, 2*p), 2)\n",
        "\n",
        "        for g in oneq_gates:\n",
        "            nm.add_all_qubit_quantum_error(err1, g)\n",
        "        nm.add_all_qubit_quantum_error(err2, \"cx\")\n",
        "        return nm\n",
        "\n",
        "    if noise_class == \"pauli\":\n",
        "        px, py, pz = params[\"px\"], params[\"py\"], params[\"pz\"]\n",
        "        pi = max(0.0, 1.0 - (px + py + pz))\n",
        "        err1 = pauli_error([(\"X\", px), (\"Y\", py), (\"Z\", pz), (\"I\", pi)])\n",
        "\n",
        "        for g in oneq_gates:\n",
        "            nm.add_all_qubit_quantum_error(err1, g)\n",
        "        return nm\n",
        "\n",
        "    if noise_class == \"amp_damp\":\n",
        "        gamma = params[\"gamma\"]\n",
        "        err1 = amplitude_damping_error(gamma)\n",
        "\n",
        "        for g in oneq_gates:\n",
        "            nm.add_all_qubit_quantum_error(err1, g)\n",
        "        return nm\n",
        "\n",
        "    raise ValueError(\"Unknown noise_class\")"
      ],
      "metadata": {
        "id": "F2KS7effnWCA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ZZ = SparsePauliOp.from_list([(\"ZZ\", 1.0)])\n",
        "\n",
        "def compute_y_true_expectation(qc_no_measure: QuantumCircuit) -> float:\n",
        "    \"\"\"\n",
        "    noiseless 기대값 y_true = <ZZ>\n",
        "    - 측정이 없는 회로를 statevector로 시뮬레이션 후 expectation 계산\n",
        "    \"\"\"\n",
        "    sv = Statevector.from_instruction(qc_no_measure)\n",
        "    val = np.real(sv.expectation_value(ZZ))\n",
        "    return float(val)"
      ],
      "metadata": {
        "id": "bX3gWjbvnxqx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_noisy_counts(qc_with_measure: QuantumCircuit, noise_model: NoiseModel, shots: int = 4096) -> dict:\n",
        "    \"\"\"\n",
        "    AerSimulator로 noisy shots 실행 후 counts(dict) 반환\n",
        "    \"\"\"\n",
        "    sim = AerSimulator(noise_model=noise_model)\n",
        "    job = sim.run(qc_with_measure, shots=shots)\n",
        "    result = job.result()\n",
        "    counts = result.get_counts(0)\n",
        "    # counts 예: {'00': 1024, '01': 980, ...}\n",
        "    return counts"
      ],
      "metadata": {
        "id": "vINw9l3AoB6X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def zz_from_counts(counts: dict) -> float:\n",
        "    shots = sum(counts.values())\n",
        "    return (\n",
        "        counts.get(\"00\", 0)\n",
        "      - counts.get(\"01\", 0)\n",
        "      - counts.get(\"10\", 0)\n",
        "      + counts.get(\"11\", 0)\n",
        "    ) / shots"
      ],
      "metadata": {
        "id": "5zu-f72-YRMn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_dataset(\n",
        "    N: int = 5600,\n",
        "    shots: int = 4096,\n",
        "    save_every: int = 200,\n",
        "    p_cx: float = 0.25,\n",
        "):\n",
        "    \"\"\"\n",
        "    (1) 회로 생성 -> (2) 노이즈 샘플링 -> (3) y_true 계산 -> (4) noisy counts 생성\n",
        "    결과는 OUT_CSV에 append 저장.\n",
        "    \"\"\"\n",
        "\n",
        "    # 이미 저장된 CSV가 있으면 이어서 생성(런타임 끊겨도 이어가기)\n",
        "    if os.path.exists(OUT_CSV):\n",
        "        prev = pd.read_csv(OUT_CSV)\n",
        "        start_idx = int(prev[\"circuit_id\"].max()) + 1 if len(prev) > 0 else 0\n",
        "        print(f\"[Resume] Existing rows={len(prev)}, start_idx={start_idx}\")\n",
        "    else:\n",
        "        start_idx = 0\n",
        "        print(\"[New] Start from 0\")\n",
        "\n",
        "    rows_buffer = []\n",
        "    t0 = time.time()\n",
        "\n",
        "    for cid in range(start_idx, N):\n",
        "        depth = random.randint(1, 30)\n",
        "\n",
        "        # (1) circuit 만들기 (측정 없는 버전)\n",
        "        qc = random_2q_circuit(depth=depth, p_cx=p_cx)\n",
        "\n",
        "        # (3) y_true (측정 없는 상태에서 계산)\n",
        "        y_true = compute_y_true_expectation(qc)\n",
        "\n",
        "        # noisy 실행용 측정 회로 복사 후 measure_all 추가\n",
        "        qc_m = qc.copy()\n",
        "        qc_m.measure_all()\n",
        "\n",
        "        # (2) 노이즈 클래스/강도 샘플링\n",
        "        noise_class = random.choice(NOISE_CLASSES)\n",
        "        params = sample_noise_params(noise_class)\n",
        "        nm = build_noise_model(noise_class, params)\n",
        "\n",
        "        # (4) noisy counts 얻기\n",
        "        counts = run_noisy_counts(qc_m, nm, shots=shots)\n",
        "\n",
        "        zz_noisy = zz_from_counts(counts)\n",
        "\n",
        "        # QuantumCircuit -> QPY(binary) -> base64(str)\n",
        "        buf = io.BytesIO()\n",
        "        qpy.dump(qc, buf)\n",
        "        qpy_b64 = base64.b64encode(buf.getvalue()).decode(\"utf-8\")\n",
        "\n",
        "\n",
        "        # 저장 레코드(최소 필드)\n",
        "        rows_buffer.append({\n",
        "            \"circuit_id\": cid,\n",
        "            \"depth\": depth,\n",
        "            \"noise_class\": noise_class,\n",
        "            \"noise_params\": json.dumps(params, ensure_ascii=False),\n",
        "            \"shots\": shots,\n",
        "            \"y_true_zz\": y_true,\n",
        "            \"zz_noisy\": zz_noisy,\n",
        "            \"qpy\": qpy_b64,\n",
        "            \"counts\": json.dumps(counts),   # dict를 문자열로 저장\n",
        "        })\n",
        "\n",
        "        # 중간 저장\n",
        "        if (cid + 1) % save_every == 0 or (cid + 1) == N:\n",
        "            df = pd.DataFrame(rows_buffer)\n",
        "            header = not os.path.exists(OUT_CSV)\n",
        "            df.to_csv(OUT_CSV, mode=\"a\", header=header, index=False)\n",
        "\n",
        "            rows_buffer = []\n",
        "            elapsed = time.time() - t0\n",
        "            print(f\"[Saved] up to circuit_id={cid} | elapsed={elapsed:.1f}s | file={OUT_CSV}\")\n",
        "\n",
        "    # 메타 저장\n",
        "    meta = {\n",
        "        \"N\": N,\n",
        "        \"shots\": shots,\n",
        "        \"save_every\": save_every,\n",
        "        \"p_cx\": p_cx,\n",
        "        \"seed\": SEED,\n",
        "        \"created_at\": time.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
        "        \"out_csv\": OUT_CSV,\n",
        "    }\n",
        "    with open(OUT_META, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(meta, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "    print(\"Done. Meta saved:\", OUT_META)"
      ],
      "metadata": {
        "id": "yitt1x2woZOU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 본 실험 (논문 예시급)\n",
        "make_dataset(N=5600, shots=4096, save_every=200)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pFP_eOV9om6j",
        "outputId": "7d018894-dbbb-491a-f726-8d00d73cba7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[New] Start from 0\n",
            "[Saved] up to circuit_id=199 | elapsed=3.0s | file=/content/drive/MyDrive/qem_dataset/dataset_raw.csv\n",
            "[Saved] up to circuit_id=399 | elapsed=7.6s | file=/content/drive/MyDrive/qem_dataset/dataset_raw.csv\n",
            "[Saved] up to circuit_id=599 | elapsed=11.2s | file=/content/drive/MyDrive/qem_dataset/dataset_raw.csv\n",
            "[Saved] up to circuit_id=799 | elapsed=14.2s | file=/content/drive/MyDrive/qem_dataset/dataset_raw.csv\n",
            "[Saved] up to circuit_id=999 | elapsed=17.1s | file=/content/drive/MyDrive/qem_dataset/dataset_raw.csv\n",
            "[Saved] up to circuit_id=1199 | elapsed=21.9s | file=/content/drive/MyDrive/qem_dataset/dataset_raw.csv\n",
            "[Saved] up to circuit_id=1399 | elapsed=25.5s | file=/content/drive/MyDrive/qem_dataset/dataset_raw.csv\n",
            "[Saved] up to circuit_id=1599 | elapsed=28.4s | file=/content/drive/MyDrive/qem_dataset/dataset_raw.csv\n",
            "[Saved] up to circuit_id=1799 | elapsed=31.4s | file=/content/drive/MyDrive/qem_dataset/dataset_raw.csv\n",
            "[Saved] up to circuit_id=1999 | elapsed=36.2s | file=/content/drive/MyDrive/qem_dataset/dataset_raw.csv\n",
            "[Saved] up to circuit_id=2199 | elapsed=39.5s | file=/content/drive/MyDrive/qem_dataset/dataset_raw.csv\n",
            "[Saved] up to circuit_id=2399 | elapsed=42.6s | file=/content/drive/MyDrive/qem_dataset/dataset_raw.csv\n",
            "[Saved] up to circuit_id=2599 | elapsed=45.7s | file=/content/drive/MyDrive/qem_dataset/dataset_raw.csv\n",
            "[Saved] up to circuit_id=2799 | elapsed=51.5s | file=/content/drive/MyDrive/qem_dataset/dataset_raw.csv\n",
            "[Saved] up to circuit_id=2999 | elapsed=54.9s | file=/content/drive/MyDrive/qem_dataset/dataset_raw.csv\n",
            "[Saved] up to circuit_id=3199 | elapsed=58.0s | file=/content/drive/MyDrive/qem_dataset/dataset_raw.csv\n",
            "[Saved] up to circuit_id=3399 | elapsed=61.0s | file=/content/drive/MyDrive/qem_dataset/dataset_raw.csv\n",
            "[Saved] up to circuit_id=3599 | elapsed=66.1s | file=/content/drive/MyDrive/qem_dataset/dataset_raw.csv\n",
            "[Saved] up to circuit_id=3799 | elapsed=69.1s | file=/content/drive/MyDrive/qem_dataset/dataset_raw.csv\n",
            "[Saved] up to circuit_id=3999 | elapsed=72.2s | file=/content/drive/MyDrive/qem_dataset/dataset_raw.csv\n",
            "[Saved] up to circuit_id=4199 | elapsed=75.1s | file=/content/drive/MyDrive/qem_dataset/dataset_raw.csv\n",
            "[Saved] up to circuit_id=4399 | elapsed=80.3s | file=/content/drive/MyDrive/qem_dataset/dataset_raw.csv\n",
            "[Saved] up to circuit_id=4599 | elapsed=83.6s | file=/content/drive/MyDrive/qem_dataset/dataset_raw.csv\n",
            "[Saved] up to circuit_id=4799 | elapsed=86.9s | file=/content/drive/MyDrive/qem_dataset/dataset_raw.csv\n",
            "[Saved] up to circuit_id=4999 | elapsed=90.6s | file=/content/drive/MyDrive/qem_dataset/dataset_raw.csv\n",
            "[Saved] up to circuit_id=5199 | elapsed=95.2s | file=/content/drive/MyDrive/qem_dataset/dataset_raw.csv\n",
            "[Saved] up to circuit_id=5399 | elapsed=98.2s | file=/content/drive/MyDrive/qem_dataset/dataset_raw.csv\n",
            "[Saved] up to circuit_id=5599 | elapsed=101.2s | file=/content/drive/MyDrive/qem_dataset/dataset_raw.csv\n",
            "Done. Meta saved: /content/drive/MyDrive/qem_dataset/run_meta.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================\n",
        "# Regression-only ML-QEM (paper-style features) + baselines\n",
        "# - No classification\n",
        "# - Feature: measurement (per-bitstring) + mean/var + gate features + depth\n",
        "# - Compare vs baseline(no mitigation) and optional baseline regression\n",
        "# =========================================================\n",
        "\n",
        "import os, json, base64, io\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from qiskit import qpy\n",
        "\n",
        "# -------------------------\n",
        "# 0) Reproducibility\n",
        "# -------------------------\n",
        "def set_seed(seed: int = 42):\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "# -------------------------\n",
        "# 1) counts -> feature\n",
        "#    - per-bitstring feature (paper: \"counts transformed to separate features\")\n",
        "#    - mean / variance of measurement outcomes\n",
        "# -------------------------\n",
        "BITSTR_2Q = [\"00\", \"01\", \"10\", \"11\"]\n",
        "\n",
        "def counts_to_prob_vec(counts: dict, bit_list=BITSTR_2Q) -> np.ndarray:\n",
        "    \"\"\"counts dict -> probability vector in fixed bitstring order.\"\"\"\n",
        "    shots = max(1, sum(counts.values()))\n",
        "    return np.array([counts.get(b, 0) / shots for b in bit_list], dtype=np.float32)\n",
        "\n",
        "def mean_var_from_counts_intmap(counts: dict) -> tuple[float, float]:\n",
        "    \"\"\"\n",
        "    Treat bitstring as integer outcome (e.g., '10'->2), compute mean/variance.\n",
        "    Matches paper's mean/variance idea from measurement outcomes.\n",
        "    \"\"\"\n",
        "    shots = max(1, sum(counts.values()))\n",
        "    mu = 0.0\n",
        "    e2 = 0.0\n",
        "    for b, c in counts.items():\n",
        "        v = int(b, 2)\n",
        "        p = c / shots\n",
        "        mu += v * p\n",
        "        e2 += (v**2) * p\n",
        "    var = e2 - mu**2\n",
        "    return float(mu), float(var)\n",
        "\n",
        "# -------------------------\n",
        "# 2) qpy -> gate features\n",
        "#    paper: gate sequence -> each gate type as separate feature\n",
        "# -------------------------\n",
        "GATE_LIST = [\"rx\", \"ry\", \"rz\", \"x\", \"y\", \"z\", \"cx\"]\n",
        "\n",
        "def qpy_b64_to_circuit(qpy_b64: str):\n",
        "    raw = base64.b64decode(qpy_b64.encode(\"utf-8\"))\n",
        "    buf = io.BytesIO(raw)\n",
        "    circuits = qpy.load(buf)\n",
        "    return circuits[0]\n",
        "\n",
        "def gate_features(qc, gate_list=GATE_LIST, mode=\"count\") -> np.ndarray:\n",
        "    \"\"\"\n",
        "    mode:\n",
        "      - 'count': count occurrences of each gate type\n",
        "      - 'binary': 0/1 whether gate appears\n",
        "    \"\"\"\n",
        "    counts = {g: 0 for g in gate_list}\n",
        "    for inst, qargs, cargs in qc.data:\n",
        "        name = inst.name\n",
        "        if name in counts:\n",
        "            counts[name] += 1\n",
        "\n",
        "    vec = np.array([counts[g] for g in gate_list], dtype=np.float32)\n",
        "    if mode == \"binary\":\n",
        "        vec = (vec > 0).astype(np.float32)\n",
        "    return vec\n",
        "\n",
        "# -------------------------\n",
        "# 3) Build feature matrix X, targets\n",
        "# -------------------------\n",
        "def build_dataset(csv_path: str,\n",
        "                  require_2q=True,\n",
        "                  gate_mode=\"count\",\n",
        "                  use_prob=True):\n",
        "    \"\"\"\n",
        "    Reads dataset_raw.csv and builds:\n",
        "      X: [meas_feature(4) + mean + var + gate_feature(len(GATE_LIST)) + depth]\n",
        "      y_true: noiseless expectation value (target)\n",
        "      y_noisy: noisy expectation value (baseline)\n",
        "    \"\"\"\n",
        "    df = pd.read_csv(csv_path)\n",
        "\n",
        "    X_list, y_true_list, y_noisy_list = [], [], []\n",
        "\n",
        "    for i, row in df.iterrows():\n",
        "        counts = json.loads(row[\"counts\"])\n",
        "        # Optional safety check: ensure 2-qubit bitstrings\n",
        "        if require_2q:\n",
        "            k = next(iter(counts.keys()))\n",
        "            if len(k) != 2:\n",
        "                raise ValueError(f\"2큐비트 row가 섞였습니다 (row={i}, key='{k}')\")\n",
        "\n",
        "        meas_vec = counts_to_prob_vec(counts) if use_prob else \\\n",
        "                   np.array([counts.get(b, 0) for b in BITSTR_2Q], dtype=np.float32)\n",
        "\n",
        "        mu, var = mean_var_from_counts_intmap(counts)\n",
        "\n",
        "        qc = qpy_b64_to_circuit(row[\"qpy\"])\n",
        "        g_vec = gate_features(qc, mode=gate_mode)\n",
        "\n",
        "        depth = float(row[\"depth\"])\n",
        "\n",
        "        feat = np.concatenate([\n",
        "            meas_vec,\n",
        "            np.array([mu, var], dtype=np.float32),\n",
        "            g_vec,\n",
        "            np.array([depth], dtype=np.float32),\n",
        "        ])\n",
        "\n",
        "        X_list.append(feat)\n",
        "        y_true_list.append(float(row[\"y_true_zz\"]))\n",
        "        y_noisy_list.append(float(row[\"zz_noisy\"]))\n",
        "\n",
        "    X = np.vstack(X_list).astype(np.float32)\n",
        "    y_true = np.array(y_true_list, dtype=np.float32)\n",
        "    y_noisy = np.array(y_noisy_list, dtype=np.float32)\n",
        "    return X, y_true, y_noisy\n",
        "\n",
        "# -------------------------\n",
        "# 4) PyTorch regressor (MLP)\n",
        "# -------------------------\n",
        "class NPDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = torch.from_numpy(X).float()\n",
        "        self.y = torch.from_numpy(y).float().view(-1, 1)\n",
        "    def __len__(self): return len(self.X)\n",
        "    def __getitem__(self, idx): return self.X[idx], self.y[idx]\n",
        "\n",
        "class RegressorMLP(nn.Module):\n",
        "    def __init__(self, in_dim: int, hidden=(128, 64), dropout=0.1):\n",
        "        super().__init__()\n",
        "        layers = []\n",
        "        prev = in_dim\n",
        "        for h in hidden:\n",
        "            layers += [nn.Linear(prev, h), nn.ReLU(), nn.Dropout(dropout)]\n",
        "            prev = h\n",
        "        layers += [nn.Linear(prev, 1)]\n",
        "        self.net = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x): return self.net(x)\n",
        "\n",
        "def train_regressor(model, X_tr, y_tr, X_val, y_val,\n",
        "                    lr=1e-3, batch=64, epochs=400,\n",
        "                    patience=40, device=\"cpu\"):\n",
        "    \"\"\"\n",
        "    Train MLP regressor with early stopping on val MSE.\n",
        "    \"\"\"\n",
        "    opt = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    loss_fn = nn.MSELoss()\n",
        "\n",
        "    tr_loader = DataLoader(NPDataset(X_tr, y_tr), batch_size=batch, shuffle=True)\n",
        "    val_loader = DataLoader(NPDataset(X_val, y_val), batch_size=batch, shuffle=False)\n",
        "\n",
        "    best_val = float(\"inf\")\n",
        "    best_state = None\n",
        "    bad = 0\n",
        "\n",
        "    for ep in range(1, epochs + 1):\n",
        "        model.train()\n",
        "        for xb, yb in tr_loader:\n",
        "            xb, yb = xb.to(device), yb.to(device)\n",
        "            pred = model(xb)\n",
        "            loss = loss_fn(pred, yb)\n",
        "            opt.zero_grad()\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            vals = []\n",
        "            for xb, yb in val_loader:\n",
        "                xb, yb = xb.to(device), yb.to(device)\n",
        "                vals.append(loss_fn(model(xb), yb).item())\n",
        "            val_mse = float(np.mean(vals))\n",
        "\n",
        "        if val_mse < best_val - 1e-10:\n",
        "            best_val = val_mse\n",
        "            best_state = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n",
        "            bad = 0\n",
        "        else:\n",
        "            bad += 1\n",
        "\n",
        "        if ep % 50 == 0:\n",
        "            print(f\"[Reg] ep={ep:4d}  val_mse={val_mse:.6f}  best={best_val:.6f}  bad={bad}/{patience}\")\n",
        "\n",
        "        if bad >= patience:\n",
        "            print(f\"[Reg] Early stop at ep={ep}, best_val={best_val:.6f}\")\n",
        "            break\n",
        "\n",
        "    if best_state is not None:\n",
        "        model.load_state_dict(best_state)\n",
        "    return model\n",
        "\n",
        "@torch.no_grad()\n",
        "def predict_regressor(model, X, device=\"cpu\") -> np.ndarray:\n",
        "    model.eval()\n",
        "    y = model(torch.from_numpy(X).to(device)).cpu().numpy().reshape(-1)\n",
        "    return y\n",
        "\n",
        "# -------------------------\n",
        "# 5) Evaluation helpers\n",
        "# -------------------------\n",
        "def eval_metrics(y_true, y_pred, name=\"\"):\n",
        "    mse = mean_squared_error(y_true, y_pred)\n",
        "    mae = mean_absolute_error(y_true, y_pred)\n",
        "    print(f\"\\n[{name}] MSE={mse:.6f}  MAE={mae:.6f}\")\n",
        "    return mse, mae\n",
        "\n",
        "def mitigation_stats(y_true, y_noisy, y_miti, name=\"Mitigation\"):\n",
        "    err_noisy = np.abs(y_true - y_noisy)\n",
        "    err_miti  = np.abs(y_true - y_miti)\n",
        "    print(f\"\\n[{name}] mean|true-noisy|     = {float(np.mean(err_noisy)):.6f}\")\n",
        "    print(f\"[{name}] mean|true-mitigated| = {float(np.mean(err_miti)):.6f}\")\n",
        "    print(f\"[{name}] improved fraction    = {float(np.mean(err_miti < err_noisy)):.6f}\")\n",
        "\n",
        "# -------------------------\n",
        "# 6) Main: regression-only pipeline + baselines\n",
        "# -------------------------\n",
        "def run_regression_only_experiment(\n",
        "    csv_path: str,\n",
        "    test_size=0.2,\n",
        "    seed=42,\n",
        "    scaler_type=\"minmax\",   # 'minmax' (paper-style normalization) or 'standard'\n",
        "    gate_mode=\"count\",      # 'count' or 'binary'\n",
        "    device=None,\n",
        "):\n",
        "    \"\"\"\n",
        "    Runs:\n",
        "      (A) Baseline-0: No mitigation -> predict = zz_noisy\n",
        "      (B) Baseline-1: Simple regression with ONLY measurement prob features (+mean/var) (optional reference)\n",
        "      (C) Ours: Regression with full paper-style features (meas + mean/var + gate + depth)\n",
        "    \"\"\"\n",
        "    set_seed(seed)\n",
        "    if device is None:\n",
        "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "    # ---- Full feature dataset (paper-style)\n",
        "    X_full, y_true, y_noisy = build_dataset(\n",
        "        csv_path,\n",
        "        require_2q=True,\n",
        "        gate_mode=gate_mode,\n",
        "        use_prob=True\n",
        "    )\n",
        "    print(f\"[Loaded] X_full={X_full.shape}  y_true={y_true.shape}\")\n",
        "\n",
        "    # Train/test split (same indices for all comparisons)\n",
        "    idx = np.arange(len(y_true))\n",
        "    tr_idx, te_idx = train_test_split(idx, test_size=test_size, random_state=seed)\n",
        "\n",
        "    Xtr_full, Xte_full = X_full[tr_idx], X_full[te_idx]\n",
        "    ytr, yte = y_true[tr_idx], y_true[te_idx]\n",
        "    ynoisy_te = y_noisy[te_idx]\n",
        "\n",
        "    # ---- Baseline-0: no mitigation\n",
        "    print(\"\\n========== Baseline-0: No mitigation (predict = zz_noisy) ==========\")\n",
        "    eval_metrics(yte, ynoisy_te, name=\"NoMitigation\")\n",
        "    # mitigation_stats 의미는 '모델'이 없으니 생략\n",
        "\n",
        "    # ---- Scaling for NN stability\n",
        "    if scaler_type == \"minmax\":\n",
        "        scaler_full = MinMaxScaler()\n",
        "    else:\n",
        "        scaler_full = StandardScaler()\n",
        "\n",
        "    Xtr_full_s = scaler_full.fit_transform(Xtr_full).astype(np.float32)\n",
        "    Xte_full_s = scaler_full.transform(Xte_full).astype(np.float32)\n",
        "\n",
        "    # internal train/val split\n",
        "    Xtr_s, Xval_s, ytr2, yval2 = train_test_split(\n",
        "        Xtr_full_s, ytr, test_size=0.2, random_state=seed\n",
        "    )\n",
        "\n",
        "    # ---- (C) Ours: full-feature regressor\n",
        "    print(\"\\n========== Ours: Regression (full features) ==========\")\n",
        "    model_full = RegressorMLP(in_dim=Xtr_full_s.shape[1], hidden=(128, 64), dropout=0.1).to(device)\n",
        "    model_full = train_regressor(\n",
        "        model_full, Xtr_s, ytr2, Xval_s, yval2,\n",
        "        lr=1e-3, batch=64, epochs=400, patience=40,\n",
        "        device=device\n",
        "    )\n",
        "\n",
        "    ypred_full = predict_regressor(model_full, Xte_full_s, device=device)\n",
        "    eval_metrics(yte, ypred_full, name=\"Ours(full)\")\n",
        "    mitigation_stats(yte, ynoisy_te, ypred_full, name=\"Ours(full) vs Noisy\")\n",
        "\n",
        "    # ---- (B) Baseline-1: simpler regression (measurement probs + mean/var only)\n",
        "    # feature slice: meas(4) + mean + var = first 6 dims\n",
        "    # (논문 feature 중 gate/depth 제외한 약한 베이스라인으로 비교)\n",
        "    print(\"\\n========== Baseline-1: Regression (meas probs + mean/var only) ==========\")\n",
        "    X_meas = X_full[:, :6]\n",
        "    Xtr_m, Xte_m = X_meas[tr_idx], X_meas[te_idx]\n",
        "\n",
        "    if scaler_type == \"minmax\":\n",
        "        scaler_m = MinMaxScaler()\n",
        "    else:\n",
        "        scaler_m = StandardScaler()\n",
        "\n",
        "    Xtr_m_s = scaler_m.fit_transform(Xtr_m).astype(np.float32)\n",
        "    Xte_m_s = scaler_m.transform(Xte_m).astype(np.float32)\n",
        "\n",
        "    Xtrm_s, Xvalm_s, ytrm, yvalm = train_test_split(\n",
        "        Xtr_m_s, ytr, test_size=0.2, random_state=seed\n",
        "    )\n",
        "\n",
        "    model_meas = RegressorMLP(in_dim=Xtr_m_s.shape[1], hidden=(64, 32), dropout=0.1).to(device)\n",
        "    model_meas = train_regressor(\n",
        "        model_meas, Xtrm_s, ytrm, Xvalm_s, yvalm,\n",
        "        lr=1e-3, batch=64, epochs=400, patience=40,\n",
        "        device=device\n",
        "    )\n",
        "\n",
        "    ypred_meas = predict_regressor(model_meas, Xte_m_s, device=device)\n",
        "    eval_metrics(yte, ypred_meas, name=\"Baseline-1(meas)\")\n",
        "    mitigation_stats(yte, ynoisy_te, ypred_meas, name=\"Baseline-1(meas) vs Noisy\")\n",
        "\n",
        "    # ---- Summary comparison (MAE 기준으로 한 줄 비교)\n",
        "    mae_noisy = mean_absolute_error(yte, ynoisy_te)\n",
        "    mae_meas  = mean_absolute_error(yte, ypred_meas)\n",
        "    mae_full  = mean_absolute_error(yte, ypred_full)\n",
        "\n",
        "    print(\"\\n========== Summary (MAE lower is better) ==========\")\n",
        "    print(f\"NoMitigation(zz_noisy) : {mae_noisy:.6f}\")\n",
        "    print(f\"Baseline-1(meas only)  : {mae_meas:.6f}\")\n",
        "    print(f\"Ours(full features)    : {mae_full:.6f}\")\n",
        "\n",
        "    return {\n",
        "        \"model_full\": model_full,\n",
        "        \"scaler_full\": scaler_full,\n",
        "        \"model_meas\": model_meas,\n",
        "        \"scaler_meas\": scaler_m,\n",
        "        \"test_indices\": te_idx,\n",
        "    }\n",
        "\n",
        "# =========================================================\n",
        "# Run (Colab)\n",
        "# =========================================================\n",
        "results = run_regression_only_experiment(\n",
        "    \"/content/drive/MyDrive/qem_dataset/dataset_raw.csv\",\n",
        "    test_size=0.2,\n",
        "    seed=42,\n",
        "    scaler_type=\"minmax\",  # 논문처럼 0~1 정규화 느낌을 원하면 minmax 추천\n",
        "    gate_mode=\"count\",     # gate를 'binary'로 바꾸면 \"게이트 존재 여부\" 버전\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nqMnGzAlo16m",
        "outputId": "aa2d5985-0761-4c2d-aee6-d7ae24659b00"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1388914033.py:77: DeprecationWarning: Treating CircuitInstruction as an iterable is deprecated legacy behavior since Qiskit 1.2, and will be removed in Qiskit 3.0. Instead, use the `operation`, `qubits` and `clbits` named attributes.\n",
            "  for inst, qargs, cargs in qc.data:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Loaded] X_full=(5600, 14)  y_true=(5600,)\n",
            "\n",
            "========== Baseline-0: No mitigation (predict = zz_noisy) ==========\n",
            "\n",
            "[NoMitigation] MSE=0.007062  MAE=0.052443\n",
            "\n",
            "========== Ours: Regression (full features) ==========\n",
            "[Reg] ep=  50  val_mse=0.004163  best=0.003967  bad=6/40\n",
            "[Reg] ep= 100  val_mse=0.004080  best=0.003920  bad=14/40\n",
            "[Reg] Early stop at ep=126, best_val=0.003920\n",
            "\n",
            "[Ours(full)] MSE=0.003787  MAE=0.043391\n",
            "\n",
            "[Ours(full) vs Noisy] mean|true-noisy|     = 0.052443\n",
            "[Ours(full) vs Noisy] mean|true-mitigated| = 0.043391\n",
            "[Ours(full) vs Noisy] improved fraction    = 0.540179\n",
            "\n",
            "========== Baseline-1: Regression (meas probs + mean/var only) ==========\n",
            "[Reg] ep=  50  val_mse=0.004032  best=0.003970  bad=4/40\n",
            "[Reg] ep= 100  val_mse=0.004108  best=0.003873  bad=11/40\n",
            "[Reg] ep= 150  val_mse=0.004107  best=0.003837  bad=33/40\n",
            "[Reg] Early stop at ep=157, best_val=0.003837\n",
            "\n",
            "[Baseline-1(meas)] MSE=0.003704  MAE=0.041703\n",
            "\n",
            "[Baseline-1(meas) vs Noisy] mean|true-noisy|     = 0.052443\n",
            "[Baseline-1(meas) vs Noisy] mean|true-mitigated| = 0.041703\n",
            "[Baseline-1(meas) vs Noisy] improved fraction    = 0.568750\n",
            "\n",
            "========== Summary (MAE lower is better) ==========\n",
            "NoMitigation(zz_noisy) : 0.052443\n",
            "Baseline-1(meas only)  : 0.041703\n",
            "Ours(full features)    : 0.043391\n"
          ]
        }
      ]
    }
  ]
}